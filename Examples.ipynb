{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-06T11:30:49.296970Z",
     "start_time": "2025-02-06T11:30:49.244700Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hx-gpu3/anaconda3/envs/feng/lib/python3.8/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from Script.utils import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-27T12:46:22.326109Z",
     "start_time": "2024-06-27T12:46:22.288132Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "data_dir = './Data/data_cn/'\n",
    "rundata_dir = './Data/rundata_cn/'\n",
    "df=pd.read_csv(data_dir+\"experiment_index.csv\", index_col=0)\n",
    "df = df.sort_values(by='yield')\n",
    "df.reset_index(drop=True, inplace=True)\n",
    "df['entry'] = df.index\n",
    "df.set_index('entry', inplace=True)\n",
    "ar_ha_smi=df['Aryl_halide_SMILES'].tolist()\n",
    "add_smi=df['Additive_SMILES'].tolist()\n",
    "base_smi=df['Base_SMILES'].tolist()\n",
    "ligand_smi=df['Ligand_SMILES'].tolist()\n",
    "yield_value=np.array(df['yield'].tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-27T12:46:24.854579Z",
     "start_time": "2024-06-27T12:46:24.847085Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The size of chemical space is: 3955\n"
     ]
    }
   ],
   "source": [
    "target = 'yield'\n",
    "defined_chemical_space = {'Aryl_halide_SMILES':sorted(list(set(ar_ha_smi))), \n",
    "                          'Additive_SMILES':sorted(list(set(add_smi))), \n",
    "                          'Base_SMILES':sorted(list(set(base_smi))),\n",
    "                          'Ligand_SMILES':sorted(list(set(ligand_smi))), \n",
    "                          }\n",
    "\n",
    "domain=df.drop(['yield'],axis=1)\n",
    "print('The size of chemical space is: %d'%len(domain))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reaction Optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run seed: 7\n",
      "Run seed: 4\n",
      "Run seed: 8\n",
      "Run seed: 9\n",
      "Run seed: 2\n",
      "Run seed: 5\n",
      "Run seed: 3\n",
      "Run seed: 10\n",
      "Run seed: 1\n",
      "Run seed: 6\n",
      "Run seed: 12\n",
      "Run seed: 11\n",
      "Run seed: 0\n",
      "Run seed: 13\n",
      "Run seed: 14\n",
      "Run seed: 15\n",
      "Run seed: 16\n",
      "Run seed: 17\n",
      "Run seed: 18\n",
      "Run seed: 19\n",
      "Run seed: 20\n",
      "Run seed: 21\n",
      "Run seed: 22\n",
      "Run seed: 23\n",
      "Run seed: 24\n",
      "Run seed: 25\n",
      "Run seed: 26\n",
      "Run seed: 27\n",
      "Run seed: 28\n",
      "Run seed: 29\n",
      "Run seed: 30\n",
      "Run seed: 31\n",
      "Run seed: 32\n",
      "Run seed: 33\n",
      "Run seed: 34\n",
      "Run seed: 35\n",
      "Run seed: 36\n",
      "Run seed: 37\n",
      "Run seed: 38\n",
      "Run seed: 39\n",
      "Run seed: 40\n",
      "Run seed: 41\n",
      "Run seed: 42\n",
      "Run seed: 43\n",
      "Run seed: 44\n",
      "Run seed: 45\n",
      "Run seed: 46\n",
      "Run seed: 47\n",
      "Run seed: 48\n",
      "Run seed: 49\n",
      "Run seed: 50\n",
      "Run seed: 51\n",
      "Run seed: 52\n",
      "Run seed: 53\n",
      "Run seed: 54\n",
      "Run seed: 55\n",
      "Run seed: 56\n",
      "Run seed: 57\n",
      "Run seed: 58\n",
      "Run seed: 59\n",
      "Run seed: 60\n",
      "Run seed: 61\n",
      "Run seed: 62\n",
      "Run seed: 63\n",
      "Run seed: 64\n",
      "Run seed: 65\n",
      "Run seed: 66\n",
      "Run seed: 67\n",
      "Run seed: 68\n",
      "Run seed: 69\n",
      "Run seed: 70\n",
      "Run seed: 71\n",
      "Run seed: 72\n",
      "Run seed: 73\n",
      "Run seed: 74\n",
      "Run seed: 75\n",
      "Run seed: 76\n",
      "Run seed: 77\n",
      "Run seed: 78\n",
      "Run seed: 79\n",
      "Run seed: 80\n",
      "Run seed: 81\n",
      "Run seed: 82\n",
      "Run seed: 83\n",
      "Run seed: 84\n",
      "Run seed: 85\n",
      "Run seed: 86\n",
      "Run seed: 87\n",
      "Run seed: 88\n",
      "Run seed: 89\n",
      "Run seed: 90\n",
      "Run seed: 91\n",
      "Run seed: 92\n",
      "Run seed: 93\n",
      "Run seed: 94\n",
      "Run seed: 95\n",
      "Run seed: 96\n",
      "Run seed: 97\n",
      "Run seed: 98\n",
      "Run seed: 99\n",
      "./Data/rundata_cn/results_optimization/ourwork-50-20-seed0_dft_GB_73.npy\n",
      "Data save in: ourwork-50-20-seed0_dft_GB_total.npy\n"
     ]
    }
   ],
   "source": [
    "from joblib import Parallel, delayed\n",
    "random_state = 0\n",
    "des_name = 'dft' #'ohe','mordred','dft','alldes'\n",
    "model = 'Ridge'#'DT','ET','GB','KNR','KRR','LSVR','RF','Ridge','SVR','automl','gridsearch',\n",
    "cc_rate1 = 0.5 # 0-1 exploration proportion of the first Stage\n",
    "cc_rate2 = 0.2 # 0-1 exploration proportion of the second Stage\n",
    "run_time = 120 #120s\n",
    "per_run_time = 30 #30s\n",
    "task = f'ourwork-{int(cc_rate1*100)}-{int(cc_rate2*100)}-seed' + str(random_state)\n",
    "\n",
    "desc_map={}\n",
    "if des_name not in ['ohe','mordred','dft','alldes']:\n",
    "    print('Error: The selected descriptor is not supported.')\n",
    "elif des_name == 'alldes':\n",
    "    desc_map = np.load('./Data/data_cn/all_desc_map.npy',allow_pickle=True).item()\n",
    "else:\n",
    "    for i in glob.glob(data_dir+'*.csv'):\n",
    "        if i.split('/')[-1].split('.')[0].split('_')[-1]==des_name:     \n",
    "            tem_data=np.array(pd.read_csv(i))\n",
    "            for j in range(len(tem_data)):\n",
    "                if des_name in ['ohe','mordred']:\n",
    "                    desc_map[tem_data[j][0]]=tem_data[j][1:]\n",
    "                elif des_name=='dft':\n",
    "                    desc_map[tem_data[j][1]]=tem_data[j][2:]                                   \n",
    "desc_domain = getdescdomain(domain,desc_map,defined_chemical_space)\n",
    "norun_seed = []\n",
    "for seed in range(100):\n",
    "    if os.path.exists(rundata_dir+f'{task}_{des_name}_{model}_{seed}.npy'):   \n",
    "        continue  \n",
    "    else:\n",
    "        norun_seed.append(seed)\n",
    "if model in  ['gridsearch','DT','ET','GB','KNR','KRR','LSVR','RF','Ridge','SVR']:\n",
    "    Parallel(n_jobs=-1)(delayed(yield_optimization_single_line)(seed=seed, domain = domain, desc_domain = desc_domain, model = model, \\\n",
    "                                                                des_name = des_name,random_state=random_state,tem_cc1num=(3955*cc_rate1), \\\n",
    "                                                                tem_cc2num=int(3955*cc_rate2),task = task,run_time = run_time,per_run_time = per_run_time ) for seed in norun_seed) \n",
    "elif model == 'automl':\n",
    "    for seed in norun_seed:\n",
    "        yield_optimization_single_line(seed=seed, domain = domain, desc_domain = desc_domain, model = model, \\\n",
    "                                                                des_name = des_name,random_state=random_state,tem_cc1num=(3955*cc_rate1), \\\n",
    "                                                                tem_cc2num=int(3955*cc_rate2),task = task,run_time = run_time,per_run_time = per_run_time )   \n",
    "total_results = get_total_results(rundata_dir+f'results_optimization/{task}_{des_name}_{model}_*.npy',start=0,end=100) \n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "176.25px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
